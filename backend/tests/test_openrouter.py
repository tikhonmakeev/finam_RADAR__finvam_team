"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å OpenRouter
"""
import asyncio
import os
from dotenv import load_dotenv

load_dotenv()

async def test_openrouter():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ OpenRouter."""
    from backend.ai_model.llm_client import LLMClient
    
    print("üåê –¢–µ—Å—Ç–∏—Ä—É–µ–º OpenRouter –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ API –∫–ª—é—á —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
    if not os.getenv('MARSH_API_KEY'):
        print("‚ùå –û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω MARSH_API_KEY –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
        print("–î–æ–±–∞–≤—å—Ç–µ –≤ .env —Ñ–∞–π–ª:")
        print("MARSH_API_KEY=–≤–∞—à_–∫–ª—é—á_–æ—Ç_openrouter")
        print("OPENROUTER_BASE_URL=https://openrouter.ai/api/v1")
        print("OPENROUTER_MODEL=anthropic/claude-3.5-sonnet")
        print("LLM_PROVIDER=openrouter")
        return
    
    client = LLMClient()
    provider_info = await client.get_provider_info()
    
    print(f"‚úÖ –ü—Ä–æ–≤–∞–π–¥–µ—Ä: {provider_info['provider']}")
    print(f"üìä –°—Ç–∞—Ç—É—Å: {provider_info['status']}")
    if 'model' in provider_info:
        print(f"ü§ñ –ú–æ–¥–µ–ª—å: {provider_info['model']}")
    
    # –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
    test_prompt = """
    –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â—É—é —Ñ–∏–Ω–∞–Ω—Å–æ–≤—É—é –Ω–æ–≤–æ—Å—Ç—å –∏ –æ–ø—Ä–µ–¥–µ–ª–∏:
    1. –û—Å–Ω–æ–≤–Ω—É—é –∫–æ–º–ø–∞–Ω–∏—é/—Å–µ–∫—Ç–æ—Ä
    2. –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä—ã–Ω–æ–∫
    3. –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã
    
    –ù–æ–≤–æ—Å—Ç—å: "–ì–∞–∑–ø—Ä–æ–º —Å–æ–æ–±—â–∏–ª –æ —Ä–æ—Å—Ç–µ –¥–æ–±—ã—á–∏ –≥–∞–∑–∞ –Ω–∞ 15% –≤ —ç—Ç–æ–º –∫–≤–∞—Ä—Ç–∞–ª–µ. –ê–∫—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ 5%."
    """
    
    system_prompt = """
    –¢—ã ‚Äî —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫. –û—Ç–≤–µ—á–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ.
    """
    
    print("\nüß™ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å...")
    response = await client.generate_response(
        prompt=test_prompt,
        system_prompt=system_prompt,
        temperature=0.1,
        max_tokens=500
    )
    
    if response:
        print(f"‚úÖ –û—Ç–≤–µ—Ç –æ—Ç {provider_info['provider']}:")
        print("-" * 50)
        print(response)
        print("-" * 50)
    else:
        print("‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞")

async def test_available_models():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π."""
    from backend.ai_model.openrouter_client import OpenRouterClient
    
    print("\nüìã –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏...")
    
    try:
        client = OpenRouterClient()
        models = await client.get_available_models()
        
        if models:
            print(f"‚úÖ –î–æ—Å—Ç—É–ø–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(models)}")
            print("\n–¢–æ–ø-5 –º–æ–¥–µ–ª–µ–π:")
            for i, model in enumerate(models[:5]):
                print(f"  {i+1}. {model.get('id', 'Unknown')}")
                print(f"     –ö–æ–Ω—Ç–µ–∫—Å—Ç: {model.get('context_length', 'N/A')} —Ç–æ–∫–µ–Ω–æ–≤")
                print(f"     –ü–æ—Å—Ç–∞–≤—â–∏–∫: {model.get('pricing', {}).get('prompt', 'N/A')} / {model.get('pricing', {}).get('completion', 'N/A')}")
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    asyncio.run(test_openrouter())
    # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–æ–∫—É, —á—Ç–æ–±—ã –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π
    # asyncio.run(test_available_models())
