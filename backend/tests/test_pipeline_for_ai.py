"""
–ü–û–õ–ù–´–ô –¢–ï–°–¢ –ü–ê–ô–ü–õ–ê–ô–ù–ê –û–ë–†–ê–ë–û–¢–ö–ò –ù–û–í–û–°–¢–ï–ô
1. –°–æ–∑–¥–∞–Ω–∏–µ —Å–∞–º–º–∞—Ä–∏ ‚Üí 2. –¢–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Üí 3. –û—Ü–µ–Ω–∫–∞ –≤–ª–∏—è–Ω–∏—è ‚Üí 4. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ ‚Üí 5. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
"""
import sys
from pathlib import Path
import logging
import asyncio
import pandas as pd
import os
from dotenv import load_dotenv
from datetime import datetime
import json

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ PYTHONPATH
project_root = str(Path(__file__).parent.parent)
if project_root not in sys.path:
    sys.path.append(project_root)

from ai_model.news_processor import NewsProcessor, process_news_batch
from backend.db.vector_store import VectorStore

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('full_pipeline_test.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

LLM_API_URL = os.getenv('LLM_API_URL', 'http://127.0.0.1:11434')


def load_test_news():
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –ø–∞–π–ø–ª–∞–π–Ω–∞"""
    test_news = [
        # –ù–æ–≤–æ—Å—Ç–∏ –æ –ì–∞–∑–ø—Ä–æ–º–µ (–ø–æ—Ö–æ–∂–∏–µ, –Ω–æ —Å —Ä–∞–∑–Ω—ã–º–∏ –¥–µ—Ç–∞–ª—è–º–∏)
        {
            'title': '–ì–∞–∑–ø—Ä–æ–º —É–≤–µ–ª–∏—á–∏–ª –¥–æ–±—ã—á—É –≥–∞–∑–∞',
            'text': '–ö–æ–º–ø–∞–Ω–∏—è –ì–∞–∑–ø—Ä–æ–º —Å–æ–æ–±—â–∏–ª–∞ –æ —Ä–æ—Å—Ç–µ –¥–æ–±—ã—á–∏ –≥–∞–∑–∞ –Ω–∞ 10% –≤ —ç—Ç–æ–º –∫–≤–∞—Ä—Ç–∞–ª–µ. –ê–∫—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ 5%. –ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å –Ω–∞ –Ω–∞—à –∫–∞–Ω–∞–ª!',
            'source': '–¢–µ–ª–µ–≥—Ä–∞–º-–∫–∞–Ω–∞–ª 1',
            'date': '2025-01-02'
        },
        {
            'title': '–ì–∞–∑–ø—Ä–æ–º –Ω–∞—Ä–∞—Å—Ç–∏–ª –¥–æ–±—ã—á—É',
            'text': '–ü–æ –¥–∞–Ω–Ω—ã–º –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏, –ì–∞–∑–ø—Ä–æ–º —É–≤–µ–ª–∏—á–∏–ª –æ–±—ä–µ–º –¥–æ–±—ã—á–∏ –≥–∞–∑–∞ –Ω–∞ 12% –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–º –∫–≤–∞—Ä—Ç–∞–ª–µ. –ò–Ω–≤–µ—Å—Ç–æ—Ä—ã –ø–æ–∑–∏—Ç–∏–≤–Ω–æ –æ—Ü–µ–Ω–∏–ª–∏ –Ω–æ–≤–æ—Å—Ç—å.',
            'source': '–¢–µ–ª–µ–≥—Ä–∞–º-–∫–∞–Ω–∞–ª 2',
            'date': '2025-01-02'
        },
        {
            'title': '–ì–∞–∑–ø—Ä–æ–º: —Ä–µ–∫–æ—Ä–¥–Ω–∞—è –¥–æ–±—ã—á–∞',
            'text': '–ì–∞–∑–ø—Ä–æ–º —É—Å—Ç–∞–Ω–æ–≤–∏–ª —Ä–µ–∫–æ—Ä–¥ –ø–æ –¥–æ–±—ã—á–µ –≥–∞–∑–∞ - —Ä–æ—Å—Ç —Å–æ—Å—Ç–∞–≤–∏–ª 15%. –ê–∫—Ü–∏–∏ –ì–∞–∑–ø—Ä–æ–º–∞ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç —É–≤–µ—Ä–µ–Ω–Ω—ã–π —Ä–æ—Å—Ç.',
            'source': '–ù–æ–≤–æ—Å—Ç–Ω–æ–π –ø–æ—Ä—Ç–∞–ª',
            'date': '2025-01-03'
        },

        # –ù–æ–≤–æ—Å—Ç–∏ –æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö (—Ä–∞–∑–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏)
        {
            'title': 'Apple –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∞ –Ω–æ–≤—ã–π iPhone',
            'text': '–ö–æ–º–ø–∞–Ω–∏—è Apple announced –Ω–æ–≤—ã–π iPhone —Å –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–æ–º. –û–∂–∏–¥–∞–µ—Ç—Å—è —Ä–æ—Å—Ç –ø—Ä–æ–¥–∞–∂.',
            'source': 'Tech News',
            'date': '2025-01-02'
        },
        {
            'title': 'Samsung –≤—ã–ø—É—Å—Ç–∏–ª –Ω–æ–≤—ã–π Galaxy',
            'text': 'Samsung –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª –Ω–æ–≤—ã–π —Å–º–∞—Ä—Ç—Ñ–æ–Ω Galaxy —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –∫–∞–º–µ—Ä–æ–π. –ö–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏—è –Ω–∞ —Ä—ã–Ω–∫–µ —É—Å–∏–ª–∏–≤–∞–µ—Ç—Å—è.',
            'source': 'Tech Portal',
            'date': '2025-01-02'
        },

        # –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
        {
            'title': '–¶–ë –ø–æ–≤—ã—Å–∏–ª –∫–ª—é—á–µ–≤—É—é —Å—Ç–∞–≤–∫—É',
            'text': '–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –±–∞–Ω–∫ –ø–æ–≤—ã—Å–∏–ª –∫–ª—é—á–µ–≤—É—é —Å—Ç–∞–≤–∫—É –Ω–∞ 1%. –ê–Ω–∞–ª–∏—Ç–∏–∫–∏ –æ–∂–∏–¥–∞—é—Ç –¥–∞–≤–ª–µ–Ω–∏—è –Ω–∞ —Ä—ã–Ω–æ–∫ –∞–∫—Ü–∏–π.',
            'source': '–§–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∫–∞–Ω–∞–ª',
            'date': '2025-01-02'
        },
        {
            'title': '–ë–∞–Ω–∫ X —É–≤–µ–ª–∏—á–∏–ª –ø—Ä–∏–±—ã–ª—å',
            'text': '–ë–∞–Ω–∫ X —Å–æ–æ–±—â–∏–ª –æ —Ä–æ—Å—Ç–µ —á–∏—Å—Ç–æ–π –ø—Ä–∏–±—ã–ª–∏ –Ω–∞ 25% –≤ —ç—Ç–æ–º –∫–≤–∞—Ä—Ç–∞–ª–µ. –ê–∫—Ü–∏–∏ –±–∞–Ω–∫–∞ –ø–æ–∫–∞–∑–∞–ª–∏ —Ä–æ—Å—Ç.',
            'source': '–ë–∞–Ω–∫–æ–≤—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏',
            'date': '2025-01-02'
        }
    ]
    return test_news


async def test_individual_steps():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ"""
    logger.info("\n" + "=" * 80)
    logger.info("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –û–¢–î–ï–õ–¨–ù–´–• –≠–¢–ê–ü–û–í –ü–ê–ô–ü–õ–ê–ô–ù–ê")
    logger.info("=" * 80)

    processor = NewsProcessor()
    test_news = load_test_news()

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –ø–µ—Ä–≤–æ–π –Ω–æ–≤–æ—Å—Ç–∏
    sample_news = test_news[0]

    logger.info(f"\nüì∞ –¢–ï–°–¢–û–í–ê–Ø –ù–û–í–û–°–¢–¨: {sample_news['title']}")
    logger.info(f"üìù –¢–µ–∫—Å—Ç: {sample_news['text'][:100]}...")

    # 1. –¢–ï–°–¢–ò–†–£–ï–ú –ü–û–õ–ù–£–Æ –û–ë–†–ê–ë–û–¢–ö–£
    logger.info("\n1. üîÑ –ü–û–õ–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –ù–û–í–û–°–¢–ò...")
    try:
        full_result = await processor.process_news_item(sample_news)

        if full_result:
            logger.info("‚úÖ –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            logger.info(f"   üè∑Ô∏è –¢–µ–≥–∏: {', '.join(full_result.get('tags', []))}")
            logger.info(f"   üìà –í–ª–∏—è–Ω–∏–µ: {full_result.get('market_impact', {}).get('impact_level', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
            logger.info(f"   üìã –°–≤–æ–¥–∫–∞: {full_result.get('summary', '')[:100]}...")
        else:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return False
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
        return False

    return True


async def test_duplicate_detection():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
    logger.info("\n" + "=" * 80)
    logger.info("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –û–ë–ù–ê–†–£–ñ–ï–ù–ò–Ø –î–£–ë–õ–ò–ö–ê–¢–û–í")
    logger.info("=" * 80)

    processor = NewsProcessor()
    test_news = load_test_news()

    # –ë–µ—Ä–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –æ –ì–∞–∑–ø—Ä–æ–º–µ (–ø–æ—Ö–æ–∂–∏–µ)
    gazprom_news = [news for news in test_news if '–ì–∞–∑–ø—Ä–æ–º' in news['title']]

    logger.info(f"üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å—Ä–µ–¥–∏ {len(gazprom_news)} –Ω–æ–≤–æ—Å—Ç–µ–π –æ –ì–∞–∑–ø—Ä–æ–º–µ")

    results = []
    for i, news in enumerate(gazprom_news, 1):
        logger.info(f"\nüì∞ –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤–æ—Å—Ç–∏ {i}: {news['title']}")

        try:
            result = await processor.process_news_item(news)
            if result:
                results.append(result)
                logger.info(
                    f"   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–∞: —Ç–µ–≥–∏={result.get('tags', [])}, –≤–ª–∏—è–Ω–∏–µ={result.get('market_impact', {}).get('impact_level', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
            else:
                logger.error(f"   ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        except Exception as e:
            logger.error(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")

    # –ê–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    if len(results) >= 2:
        logger.info("\nüîç –ê–ù–ê–õ–ò–ó –î–£–ë–õ–ò–ö–ê–¢–û–í:")

        # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Ç–µ–≥–∞–º –∏ —Å—É—Ç–∏
        for i, result1 in enumerate(results):
            for j, result2 in enumerate(results[i + 1:], i + 1):
                tags1 = set(result1.get('tags', []))
                tags2 = set(result2.get('tags', []))

                common_tags = tags1.intersection(tags2)
                if common_tags:
                    logger.info(f"   üì∞ –ù–æ–≤–æ—Å—Ç—å {i + 1} –∏ {j + 1}: –æ–±—â–∏–µ —Ç–µ–≥–∏ {list(common_tags)} - –í–û–ó–ú–û–ñ–ù–´–ï –î–£–ë–õ–ò–ö–ê–¢–´")
                else:
                    logger.info(f"   üì∞ –ù–æ–≤–æ—Å—Ç—å {i + 1} –∏ {j + 1}: —Ä–∞–∑–Ω—ã–µ —Ç–µ–≥–∏ - –†–ê–ó–ù–´–ï –°–û–ë–´–¢–ò–Ø")


async def test_batch_processing():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    logger.info("\n" + "=" * 80)
    logger.info("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ü–ê–ö–ï–¢–ù–û–ô –û–ë–†–ê–ë–û–¢–ö–ò")
    logger.info("=" * 80)

    test_news = load_test_news()

    logger.info(f"üì¶ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–∞–∫–µ—Ç –∏–∑ {len(test_news)} –Ω–æ–≤–æ—Å—Ç–µ–π...")

    try:
        results = await process_news_batch(test_news)

        successful = [r for r in results if r is not None]
        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(successful)}/{len(test_news)}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–µ–≥–∞–º
        all_tags = []
        for result in successful:
            all_tags.extend(result.get('tags', []))

        from collections import Counter
        tag_stats = Counter(all_tags)
        logger.info(f"üè∑Ô∏è –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–≥–æ–≤: {dict(tag_stats)}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤–ª–∏—è–Ω–∏—é
        impact_stats = Counter()
        for result in successful:
            impact = result.get('market_impact', {}).get('impact_level', 'unknown')
            impact_stats[impact] += 1
        logger.info(f"üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–ª–∏—è–Ω–∏—è: {dict(impact_stats)}")

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")


async def test_news_aggregation():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ø–æ—Ö–æ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"""
    logger.info("\n" + "=" * 80)
    logger.info("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ê–ì–†–ï–ì–ê–¶–ò–ò –ù–û–í–û–°–¢–ï–ô")
    logger.info("=" * 80)

    processor = NewsProcessor()

    # –°–æ–∑–¥–∞–µ–º —è–≤–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã —Å —Ä–∞–∑–Ω—ã–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
    duplicate_news = [
        {
            'title': '–ö–æ–º–ø–∞–Ω–∏—è X —É–≤–µ–ª–∏—á–∏–ª–∞ –ø—Ä–∏–±—ã–ª—å',
            'text': '–ö–æ–º–ø–∞–Ω–∏—è X —Å–æ–æ–±—â–∏–ª–∞ –æ —Ä–æ—Å—Ç–µ —á–∏—Å—Ç–æ–π –ø—Ä–∏–±—ã–ª–∏ –Ω–∞ 20% –≤ —ç—Ç–æ–º –∫–≤–∞—Ä—Ç–∞–ª–µ. –û–∂–∏–¥–∞–µ—Ç—Å—è —Ä–æ—Å—Ç –¥–∏–≤–∏–¥–µ–Ω–¥–æ–≤.',
            'source': '–ò—Å—Ç–æ—á–Ω–∏–∫ A',
            'date': '2025-01-02'
        },
        {
            'title': '–†–æ—Å—Ç –ø—Ä–∏–±—ã–ª–∏ –∫–æ–º–ø–∞–Ω–∏–∏ X',
            'text': '–ü–æ –¥–∞–Ω–Ω—ã–º –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏, –∫–æ–º–ø–∞–Ω–∏—è X –ø–æ–∫–∞–∑–∞–ª–∞ —Ä–æ—Å—Ç —á–∏—Å—Ç–æ–π –ø—Ä–∏–±—ã–ª–∏ –Ω–∞ 20%. –ò–Ω–≤–µ—Å—Ç–æ—Ä—ã –¥–æ–≤–æ–ª—å–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏.',
            'source': '–ò—Å—Ç–æ—á–Ω–∏–∫ B',
            'date': '2025-01-02'
        },
        {
            'title': '–ö–æ–º–ø–∞–Ω–∏—è X: —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã',
            'text': '–ö–æ–º–ø–∞–Ω–∏—è X –æ—Ç—á–∏—Ç–∞–ª–∞—Å—å –æ —Ä–æ—Å—Ç–µ –ø—Ä–∏–±—ã–ª–∏ –Ω–∞ 20%. –ê–∫—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç –ø–æ–∑–∏—Ç–∏–≤–Ω—É—é –¥–∏–Ω–∞–º–∏–∫—É.',
            'source': '–ò—Å—Ç–æ—á–Ω–∏–∫ C',
            'date': '2025-01-03'
        }
    ]

    logger.info("üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —è–≤–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã...")

    results = []
    for news in duplicate_news:
        try:
            result = await processor.process_news_item(news)
            if result:
                results.append(result)
                logger.info(f"   ‚úÖ {news['source']}: {news['title']}")
        except Exception as e:
            logger.error(f"   ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {news['source']}: {e}")

    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
    if len(results) >= 2:
        logger.info("\nüìä –ê–ù–ê–õ–ò–ó –ê–ì–†–ï–ì–ê–¶–ò–ò:")

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –æ—Å–Ω–æ–≤–Ω—ã–º —Ç–µ–≥–∞–º
        news_by_tag = {}
        for result in results:
            tags = result.get('tags', [])
            main_tag = tags[0] if tags else 'unknown'
            if main_tag not in news_by_tag:
                news_by_tag[main_tag] = []
            news_by_tag[main_tag].append(result)

        for tag, news_list in news_by_tag.items():
            if len(news_list) > 1:
                logger.info(f"   üîó –¢–µ–≥ '{tag}': {len(news_list)} –ø–æ—Ö–æ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π")
                sources = [n['original_news']['source'] for n in news_list]
                logger.info(f"      –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {', '.join(sources)}")


async def test_vector_store_integration():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –≤–µ–∫—Ç–æ—Ä–Ω—ã–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ–º"""
    logger.info("\n" + "=" * 80)
    logger.info("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ò–ù–¢–ï–ì–†–ê–¶–ò–ò –° VECTOR STORE")
    logger.info("=" * 80)

    try:
        from backend.db.vector_store import VectorStore

        vector_store = VectorStore()
        test_news = load_test_news()

        logger.info("üóÑÔ∏è –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏...")

        # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –Ω–æ–≤–æ—Å—Ç–µ–π
        for i, news in enumerate(test_news[:3], 1):
            try:
                vector_store.index_news(
                    news_id=f"test_{i}",
                    text=news['text'],
                    metadata={
                        'title': news['title'],
                        'source': news['source'],
                        'date': news['date'],
                        'tags': ['test']  # –¢–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–≥–∏
                    }
                )
                logger.info(f"   ‚úÖ –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∞: {news['title']}")
            except Exception as e:
                logger.error(f"   ‚ùå –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}")

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
        logger.info("\nüîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π...")
        try:
            search_results = vector_store.query("–ì–∞–∑–ø—Ä–æ–º –¥–æ–±—ã—á–∞ –≥–∞–∑", top_k=2)
            if search_results:
                logger.info(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(search_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É '–ì–∞–∑–ø—Ä–æ–º'")
                for i, result in enumerate(search_results, 1):
                    meta = result.get('meta', {})
                    logger.info(
                        f"      {i}. {meta.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')} (—Å—Ö–æ–¥—Å—Ç–≤–æ: {result.get('score', 0):.3f})")
            else:
                logger.info("   ‚ÑπÔ∏è –ü–æ–∏—Å–∫ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

        except Exception as e:
            logger.error(f"   ‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")

    except ImportError:
        logger.warning("‚ö†Ô∏è VectorStore –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è VectorStore: {e}")


async def generate_pipeline_report():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ —Ä–∞–±–æ—Ç–µ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
    logger.info("\n" + "=" * 80)
    logger.info("–§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –ü–û –ü–ê–ô–ü–õ–ê–ô–ù–£")
    logger.info("=" * 80)

    test_news = load_test_news()
    processor = NewsProcessor()

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –æ—Ç—á–µ—Ç–∞
    all_results = []
    for news in test_news:
        try:
            result = await processor.process_news_item(news)
            if result:
                all_results.append(result)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {news['title']}: {e}")

    # –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç
    logger.info("\nüìä –°–í–û–î–ù–´–ô –û–¢–ß–ï–¢:")
    logger.info(f"üìà –í—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {len(test_news)}")
    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(all_results)}")
    logger.info(f"üìù –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {(len(all_results) / len(test_news) * 100):.1f}%")

    # –ê–Ω–∞–ª–∏–∑ —Ç–µ–≥–æ–≤
    all_tags = []
    for result in all_results:
        all_tags.extend(result.get('tags', []))

    from collections import Counter
    if all_tags:
        tag_stats = Counter(all_tags)
        logger.info(f"\nüè∑Ô∏è –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –¢–ï–ì–û–í:")
        for tag, count in tag_stats.most_common():
            logger.info(f"   {tag}: {count} –Ω–æ–≤–æ—Å—Ç–µ–π")

    # –ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è
    impact_stats = Counter()
    for result in all_results:
        impact = result.get('market_impact', {}).get('impact_level', 'unknown')
        impact_stats[impact] += 1

    logger.info(f"\nüìà –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –í–õ–ò–Ø–ù–ò–Ø:")
    for impact, count in impact_stats.most_common():
        logger.info(f"   {impact}: {count} –Ω–æ–≤–æ—Å—Ç–µ–π")

    # –ö–∞—á–µ—Å—Ç–≤–æ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
    normalization_stats = []
    for result in all_results:
        original_len = len(result['original_news']['text'])
        normalized_len = len(result.get('style_normalized', ''))
        if normalized_len > 0:
            compression = ((original_len - normalized_len) / original_len * 100)
            normalization_stats.append(compression)

    if normalization_stats:
        avg_compression = sum(normalization_stats) / len(normalization_stats)
        logger.info(f"\n‚úÇÔ∏è –≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–¨ –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–ò:")
        logger.info(f"   –°—Ä–µ–¥–Ω–µ–µ —Å–∂–∞—Ç–∏–µ: {avg_compression:.1f}%")
        logger.info(f"   –õ—É—á—à–µ–µ —Å–∂–∞—Ç–∏–µ: {max(normalization_stats):.1f}%")
        logger.info(f"   –•—É–¥—à–µ–µ —Å–∂–∞—Ç–∏–µ: {min(normalization_stats):.1f}%")


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    logger.info("üöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û –¢–ï–°–¢–ê –ü–ê–ô–ü–õ–ê–ô–ù–ê –û–ë–†–ê–ë–û–¢–ö–ò –ù–û–í–û–°–¢–ï–ô")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
    try:
        import requests
        response = requests.get(f"{LLM_API_URL}/api/tags", timeout=10)
        if response.status_code != 200:
            logger.error("‚ùå Ollama –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
            return
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
        return

    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ —Ç–µ—Å—Ç—ã
    await test_individual_steps()
    await test_duplicate_detection()
    await test_batch_processing()
    await test_news_aggregation()
    await test_vector_store_integration()
    await generate_pipeline_report()

    logger.info("\nüéâ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ü–ê–ô–ü–õ–ê–ô–ù–ê –ó–ê–í–ï–†–®–ï–ù–û!")
    logger.info("üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    logger.info("   1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–æ–∫")
    logger.info("   2. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ —ç—Ç–∞–ø—ã —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    logger.info("   3. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
    logger.info("   4. –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("\n‚èπÔ∏è –¢–µ—Å—Ç –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")